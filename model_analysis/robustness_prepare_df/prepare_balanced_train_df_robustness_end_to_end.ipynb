{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6qYM0DXBaMf",
    "outputId": "3841a534-327f-4588-d861-adc8acfff4bb"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRvRufKqm1V9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyCqQ8ULnZzE"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7PWdJKRps9H"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F549a7jZpLQ4"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/content/drive/MyDrive/master_thesis/dataset_data/end_to_end/train_df.csv')\n",
    "train_less_skewed_df = pd.read_csv('/content/drive/MyDrive/master_thesis/dataset_data/end_to_end/train_less_skewed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EsWphBC9ymF"
   },
   "outputs": [],
   "source": [
    "train_balanced_df = pd.read_csv('/content/drive/MyDrive/master_thesis/dataset_data/end_to_end/train_balanced_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqXBuWn7puFQ"
   },
   "source": [
    "# Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pg_Xkrezpv56"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2reyXx4pqlU"
   },
   "source": [
    "# Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flTtYP0DzrcW"
   },
   "outputs": [],
   "source": [
    "cases = train_df.case_id.unique()\n",
    "np.random.shuffle(cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEnNeoLfqogl"
   },
   "source": [
    "# Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Rn30Xw6qn86"
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "s = len(cases) // n\n",
    "chunks = {}\n",
    "for x in range(n):\n",
    "  chunks[x] = cases[(x*s):((x+1)*s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLBB9xGTqiPS"
   },
   "source": [
    "# Resolve overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wbwq_5wBrHS7"
   },
   "outputs": [],
   "source": [
    "for i in range(n-1):\n",
    "  i_cases = chunks[i]\n",
    "  i_df = train_df[train_df['case_id'].isin(i_cases)]\n",
    "  i_paper_ids = i_df['paper_id'].unique()\n",
    "\n",
    "  for j in range(i+1, n):\n",
    "    j_cases = chunks[j]\n",
    "    j_df = train_df[train_df['case_id'].isin(j_cases)]\n",
    "    j_paper_ids =  j_df['paper_id'].unique()\n",
    "\n",
    "    overlap_in_j = j_df[j_df['paper_id'].isin(i_paper_ids)]['case_id'].unique()\n",
    "    overlap_in_i = i_df[i_df['paper_id'].isin(j_paper_ids)]['case_id'].unique()\n",
    "    # move the cases to smaller chunk\n",
    "    if len(j_df) > len(i_df):\n",
    "      # remove cases from j and move them to i\n",
    "      chunks[j].remove(overlap_in_j)\n",
    "      chunks[i].extend(overlap_in_j)\n",
    "    else:\n",
    "      chunks[i].remove(overlap_in_i)\n",
    "      chunks[j].extend(overlap_in_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hied_xUyvcr4"
   },
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVM0VddWvhUv"
   },
   "outputs": [],
   "source": [
    "# full df chunk\n",
    "for chunk_key in chunks:\n",
    "  cases = chunks[chunk_key]\n",
    "  chunk_df = train_df[train_df['case_id'].isin(cases)]\n",
    "  chunk_name = f\"train_chunk_full_{chunk_key}.csv\"\n",
    "  chunk_df.to_csv(f'/content/drive/MyDrive/master_thesis/dataset_data/end_to_end/robustness/{chunk_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mq1G2DeNv4aF"
   },
   "outputs": [],
   "source": [
    "# less skewed df chunk\n",
    "for chunk_key in chunks:\n",
    "  cases = chunks[chunk_key]\n",
    "  chunk_df = train_less_skewed_df[train_less_skewed_df['case_id'].isin(cases)]\n",
    "  chunk_name = f\"train_chunk_less_skewed_{chunk_key}.csv\"\n",
    "  chunk_df.to_csv(f'/content/drive/MyDrive/master_thesis/dataset_data/end_to_end/robustness/{chunk_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMmsRB2Ev_e9"
   },
   "outputs": [],
   "source": [
    "# balanced df chunk\n",
    "for chunk_key in chunks:\n",
    "  cases = chunks[chunk_key]\n",
    "  chunk_df = train_balanced_df[train_balanced_df['case_id'].isin(cases)]\n",
    "  chunk_name = f\"train_chunk_balanced_{chunk_key}.csv\"\n",
    "  chunk_df.to_csv(f'/content/drive/MyDrive/master_thesis/dataset_data/end_to_end/robustness/{chunk_name}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
